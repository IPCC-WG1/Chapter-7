{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run large FaIR ensemble\n",
    "\n",
    "Runs the parameter set generated in #055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) { return false; }"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/b0110/Users/mencsm/miniconda3/envs/ar6/lib/python3.7/site-packages/openscm_runner/run.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import errno\n",
    "import fair\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from fair.constants import molwt\n",
    "from fair.ancil import natural, cmip6_volcanic, cmip6_solar\n",
    "from ar6.forcing.aerosol import ghan\n",
    "\n",
    "from openscm_units import unit_registry as ur\n",
    "from scmdata import ScmRun\n",
    "\n",
    "import openscm_runner\n",
    "from openscm_twolayermodel import TwoLayerModel\n",
    "from openscm_twolayermodel.constants import DENSITY_WATER, HEAT_CAPACITY_WATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openscm_runner.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble generation\n",
    "\n",
    "We want to ensure reproducible results that don't change when this script is re-run. Grab list of pre-generated random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data_input/random_seeds.json', 'r') as filehandle:\n",
    "    SEEDS = json.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = 1000000\n",
    "NINETY_TO_ONESIGMA = st.norm.ppf(0.95)\n",
    "F2XCO2_MEAN = 4.00\n",
    "F2XCO2_NINETY = 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I now think we have everything we need to run FaIR with\n",
    "\n",
    "Before tackling the AR6-WG3 format, let's see how they look before we let this loose on the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ssp_df = pd.read_csv(os.path.join(os.path.dirname(fair.__file__), 'SSPs/data/rcmip-emissions-annual-means-4-0-0-ssp-only.csv'))\n",
    "ssp_df = pd.read_csv('../data_input_large/rcmip-emissions-annual-means-v5-1-0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(1750,2101)\n",
    "startyear = 1750\n",
    "first_scenyear = 2015\n",
    "last_scenyear = 2100\n",
    "first_row = int(first_scenyear-startyear)\n",
    "last_row = int(last_scenyear-startyear)\n",
    "\n",
    "species = [  # in fair 1.6, order is important\n",
    "    '|CO2|MAGICC Fossil and Industrial',\n",
    "    '|CO2|MAGICC AFOLU',\n",
    "    '|CH4',\n",
    "    '|N2O',\n",
    "    '|Sulfur',\n",
    "    '|CO',\n",
    "    '|VOC',\n",
    "    '|NOx',\n",
    "    '|BC',\n",
    "    '|OC',\n",
    "    '|NH3',\n",
    "    '|CF4',\n",
    "    '|C2F6',\n",
    "    '|C6F14',\n",
    "    '|HFC23',\n",
    "    '|HFC32',\n",
    "    '|HFC4310mee',\n",
    "    '|HFC125',\n",
    "    '|HFC134a',\n",
    "    '|HFC143a',\n",
    "    '|HFC227ea',\n",
    "    '|HFC245fa',\n",
    "    '|SF6',\n",
    "    '|CFC11',\n",
    "    '|CFC12',\n",
    "    '|CFC113',\n",
    "    '|CFC114',\n",
    "    '|CFC115',\n",
    "    '|CCl4',\n",
    "    '|CH3CCl3',\n",
    "    '|HCFC22',\n",
    "    '|HCFC141b',\n",
    "    '|HCFC142b',\n",
    "    '|Halon1211',\n",
    "    '|Halon1202',\n",
    "    '|Halon1301',\n",
    "    '|Halon2402',\n",
    "    '|CH3Br',\n",
    "    '|CH3Cl',\n",
    "]\n",
    "\n",
    "# Assume that units coming out of aneris don't change. One day I'll do unit parsing\n",
    "unit_convert = np.ones(40)\n",
    "unit_convert[1] = 12/44/1000\n",
    "unit_convert[2] = 12/44/1000\n",
    "unit_convert[4] = 28/44/1000\n",
    "unit_convert[5] = 32/64\n",
    "unit_convert[8] = 14/46\n",
    "\n",
    "data_out = {}\n",
    "\n",
    "scens = ['ssp245']\n",
    "for scen in scens:\n",
    "    data_out[scen] = np.ones((351, 40)) * np.nan\n",
    "    data_out[scen][:,0] = years\n",
    "\n",
    "    years_future = [2015] + list(range(2020,2101,10))\n",
    "    for i, specie in enumerate(species):\n",
    "        data_out[scen][:first_row,i+1] = ssp_df.loc[(ssp_df['Model']=='MESSAGE-GLOBIOM')&(ssp_df['Region']=='World')&(ssp_df['Scenario']==scen)&(ssp_df['Variable'].str.endswith(specie)),str(startyear):'2014']*unit_convert[i+1]\n",
    "        f = interp1d(years_future, ssp_df.loc[(ssp_df['Model']=='MESSAGE-GLOBIOM')&(ssp_df['Region']=='World')&(ssp_df['Scenario']==scen)&(ssp_df['Variable'].str.endswith(specie)),'2015':'2100'].dropna(axis=1))\n",
    "        data_out[scen][first_row:(last_row+1), i+1] = f(np.arange(first_scenyear, last_scenyear+1))*unit_convert[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out['ssp245'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00000000e+03, 6.88899310e+00, 1.20061057e+00, 3.10186810e+02,\n",
       "       6.11111906e+00, 5.55743021e+01, 8.86564730e+02, 1.95324158e+02,\n",
       "       4.12492764e+01, 7.45734723e+00, 2.79819784e+01, 5.45095965e+01,\n",
       "       9.92314570e+00, 2.81539430e+00, 8.27090430e-01, 9.29783890e+00,\n",
       "       1.41149200e+00, 5.74232780e-01, 1.06406670e+01, 9.96574240e+01,\n",
       "       8.59875630e+00, 8.63199880e-01, 3.40069260e-02, 5.27353320e+00,\n",
       "       7.63300760e+01, 1.22766050e+02, 9.40438840e+00, 3.98671420e+00,\n",
       "       2.34765180e+00, 7.26514080e+01, 1.94712270e+01, 2.63606270e+02,\n",
       "       5.63416860e+01, 2.57301520e+01, 9.48013480e+00, 0.00000000e+00,\n",
       "       1.96944120e+00, 7.71519220e-01, 1.65258760e+02, 5.07426960e+03])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out['ssp245'][250,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in natural emissions and natural forcing\n",
    "ch4_n2o_df = pd.read_csv('../data_output/fair_wg3_natural_ch4_n2o.csv')\n",
    "ch4_n2o = ch4_n2o_df.values[:351,1:]\n",
    "\n",
    "df = pd.read_csv('../data_output/solar_erf.csv', index_col='year')\n",
    "solar_forcing = df.solar_erf.loc[1750:2100].values\n",
    "\n",
    "df = pd.read_csv('../data_output/volcanic_erf.csv', index_col='year')\n",
    "volcanic_forcing = np.zeros((351))\n",
    "volcanic_forcing[:269] = df.volcanic_erf.loc[1750:2018].values\n",
    "# ramp down last 10 years to zero according to https://www.geosci-model-dev.net/9/3461/2016/gmd-9-3461-2016.html\n",
    "volcanic_forcing[268:279] = volcanic_forcing[268] * np.linspace(1,0,11)\n",
    "volcanic_forcing[279:] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a list of dicts to run FaIR with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2804d06ca2c4324a1c84c480dd017fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ozone\n",
    "ozone_feedback = np.load('../data_input_large/fair-samples/ozone_feedback_unconstrained.npy')\n",
    "beta_ch4 = np.load('../data_input_large/fair-samples/beta_ch4_unconstrained.npy')\n",
    "beta_n2o = np.load('../data_input_large/fair-samples/beta_n2o_unconstrained.npy')\n",
    "beta_ods = np.load('../data_input_large/fair-samples/beta_ods_unconstrained.npy')\n",
    "beta_co = np.load('../data_input_large/fair-samples/beta_co_unconstrained.npy')\n",
    "beta_voc = np.load('../data_input_large/fair-samples/beta_voc_unconstrained.npy')\n",
    "beta_nox = np.load('../data_input_large/fair-samples/beta_nox_unconstrained.npy')\n",
    "\n",
    "# carbon cycle\n",
    "r0 = np.load('../data_input_large/fair-samples/r0_unconstrained.npy')\n",
    "rC = np.load('../data_input_large/fair-samples/rC_unconstrained.npy')\n",
    "rT = np.load('../data_input_large/fair-samples/rT_unconstrained.npy')\n",
    "pre_ind_co2 = np.load('../data_input_large/fair-samples/pre_ind_co2_unconstrained.npy')\n",
    "\n",
    "# aerosol\n",
    "beta_so2 = np.load('../data_input_large/fair-samples/beta_so2_unconstrained.npy')\n",
    "beta_bc = np.load('../data_input_large/fair-samples/beta_bc_unconstrained.npy')\n",
    "beta_oc = np.load('../data_input_large/fair-samples/beta_oc_unconstrained.npy')\n",
    "beta_nh3 = np.load('../data_input_large/fair-samples/beta_nh3_unconstrained.npy')\n",
    "beta = np.load('../data_input_large/fair-samples/beta_unconstrained.npy')\n",
    "aci_coeffs = np.load('../data_input_large/fair-samples/aci_coeffs.npy')\n",
    "\n",
    "# forcing\n",
    "scale_normals = np.load('../data_input_large/fair-samples/scale_normals.npy')\n",
    "trend_solar = np.load('../data_input_large/fair-samples/scale_trend_solar.npy')\n",
    "\n",
    "# climate response\n",
    "geoff_sample_df = pd.read_csv('../data_output_large/geoff_sample.csv')\n",
    "f2x = np.load('../data_input_large/fair-samples/f2x_unconstrained.npy')\n",
    "\n",
    "scen='ssp245'\n",
    "E_pi=np.zeros(40)\n",
    "# unit convert not necessary as this has been done going in\n",
    "E_pi[5]=1.22002422\n",
    "E_pi[6]=348.527359\n",
    "E_pi[7]=60.0218262\n",
    "E_pi[8]=3.87593407\n",
    "E_pi[9]=2.09777075\n",
    "E_pi[10]=15.4476682\n",
    "E_pi[11]=6.92769009\n",
    "\n",
    "arglist = []\n",
    "for i in tqdm(range(SAMPLES)):\n",
    "    # should we use RCMIP or AR6 values??\n",
    "    # do not move this out of the loop\n",
    "    C_pi=np.zeros(31)\n",
    "    C_pi[0] = pre_ind_co2[i]\n",
    "    C_pi[1]=731.406\n",
    "    C_pi[2]=273.8651\n",
    "    C_pi[3]=34.05\n",
    "    C_pi[4] = 32.28077001\n",
    "    C_pi[25]=0.00434894\n",
    "    C_pi[29]=8.75191031\n",
    "    C_pi[30]=755.7838942\n",
    "    scale = np.ones(45)\n",
    "    scale[1:3] = scale_normals[i,1:3]\n",
    "    scale[3:31] = scale_normals[i,3]\n",
    "    #scale[31] = scale_normals[i,4]\n",
    "    scale[33:35] = scale_normals[i,5:7]\n",
    "    scale[41:44] = scale_normals[i,7:10]   \n",
    "    F_solar = np.zeros(351)\n",
    "    F_solar[:270] = np.linspace(0,trend_solar[i],270) + solar_forcing[:270]*scale_normals[i,10]\n",
    "    F_solar[270:351] = trend_solar[i] + solar_forcing[270:351]*scale_normals[i,10]\n",
    "    arglist.append(\n",
    "        {\n",
    "            'ghg_forcing': 'Meinshausen',\n",
    "            'emissions': data_out[scen],\n",
    "            'natural': ch4_n2o,\n",
    "            'F_volcanic': volcanic_forcing,\n",
    "            'F_solar': solar_forcing,\n",
    "            'efficacy': np.ones(45),\n",
    "            'diagnostics': 'AR6',\n",
    "            'gir_carbon_cycle': True,\n",
    "            'aerosol_forcing': 'aerocom+ghan2',\n",
    "            'fixPre1850RCP': False,\n",
    "            'E_pi': E_pi,\n",
    "            'temperature_function': 'Geoffroy',\n",
    "            'b_tro3': np.array([beta_ch4[i], beta_n2o[i], beta_ods[i], beta_co[i], beta_voc[i], beta_nox[i]]),\n",
    "            'ozone_feedback': ozone_feedback[i],\n",
    "            'tropO3_forcing': 'thornhill-skeie',\n",
    "            'aCO2land': 0.0006394631886297174,\n",
    "            'C_pi': C_pi,\n",
    "            'F2x': f2x[i],\n",
    "            'r0': r0[i],\n",
    "            'rc': rC[i],\n",
    "            'rt': rT[i],\n",
    "            'lambda_global': -geoff_sample_df.loc[i, 'lamg'],  # this and the below only used in two-layer model\n",
    "            'ocean_heat_capacity': np.array([geoff_sample_df.loc[i, 'cmix'], geoff_sample_df.loc[i, 'cdeep']]),\n",
    "            'ocean_heat_exchange': geoff_sample_df.loc[i, 'gamma_2l'],\n",
    "            'deep_ocean_efficacy': geoff_sample_df.loc[i, 'eff'],\n",
    "            'b_aero': np.array([beta_so2[i], 0.0, 0.0, 0.0, beta_bc[i], beta_oc[i], beta_nh3[i]]),\n",
    "            'ghan_params': np.array([beta[i], aci_coeffs[i,0], aci_coeffs[i,1]]),\n",
    "            'scale': scale,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in parallel on 16 processors\n",
    "\n",
    "Depending on your machine you might want to change this number.\n",
    "\n",
    "** CHECK OUTPUT IS SAVED! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2492a245e1e84c0db20bda3f6e4b00c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_fair(args):\n",
    "    thisC, thisF, thisT, _, thisOHU, _, thisAF = fair.forward.fair_scm(**args)\n",
    "    return (\n",
    "        thisC[:,0], \n",
    "        thisF[:,31], \n",
    "        np.sum(thisF[:,35:40], axis=1),\n",
    "        thisF[:,40],\n",
    "        np.sum(thisF[:,:43], axis=1),\n",
    "        np.sum(thisF, axis=1),\n",
    "        thisT,\n",
    "        thisOHU,\n",
    "        thisAF\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(16) as pool:\n",
    "        result = list(tqdm(pool.imap(run_fair, arglist), total=SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_t = np.array(result).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_CO2, F_O3, F_dir, F_ind, F_ant, F_tot, T, OHU, AF = result_t\n",
    "\n",
    "np.save('../data_output_large/fair-samples/F_O3_unconstrained.npy', F_O3)\n",
    "np.save('../data_output_large/fair-samples/F_ERFari_unconstrained.npy', F_dir)\n",
    "np.save('../data_output_large/fair-samples/F_ERFaci_unconstrained.npy', F_ind)\n",
    "np.save('../data_output_large/fair-samples/F_anthro_unconstrained.npy', F_ant)\n",
    "np.save('../data_output_large/fair-samples/F_total_unconstrained.npy', F_tot)\n",
    "np.save('../data_output_large/fair-samples/C_CO2_unconstrained.npy', C_CO2)\n",
    "np.save('../data_output_large/fair-samples/T_unconstrained.npy', T)\n",
    "np.save('../data_output_large/fair-samples/OHU_unconstrained.npy', OHU)\n",
    "np.save('../data_output_large/fair-samples/AF_unconstrained.npy', AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fill_between(np.arange(1750,2101), np.percentile(F_O3, 5, axis=1), np.percentile(F_O3, 95, axis=1))\n",
    "pl.plot(np.arange(1750,2101), np.percentile(F_O3, 50, axis=1), color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(F_O3, 50, axis=1)[350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fill_between(np.arange(1750,2101), np.percentile(C_CO2, 5, axis=1), np.percentile(C_CO2, 95, axis=1))\n",
    "pl.plot(np.arange(1750,2101), np.percentile(C_CO2, 50, axis=1), color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.hist(C_CO2[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fill_between(np.arange(1750,2101), np.percentile(T, 5, axis=1), np.percentile(T, 95, axis=1))\n",
    "pl.plot(np.arange(1750,2101), np.percentile(T, 50, axis=1), color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
